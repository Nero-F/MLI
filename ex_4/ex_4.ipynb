{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "127369a2",
   "metadata": {},
   "source": [
    "To accomplish this task, we will use the Scikit-learn library, which is the most popular machine learning library in Python. This library contains several classification methods, such as logistic regression, support vector machines, decision trees, and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b60842c-f3b6-4ef9-a091-661665cef4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "402dec16",
   "metadata": {},
   "source": [
    "Our first step will be to load the data from the npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90396d4d-9979-4680-b1ca-24dd70fd4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"inputs.npy\")\n",
    "y = np.load(\"labels.npy\").ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72ed584a",
   "metadata": {},
   "source": [
    "Next, we will split the data into training and testing sets. The training set will be used to train our chosen model, and the test set will be used to evaluate the final performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879262a8-c84b-45a9-a4e4-e37c82a9bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "053ad1e5",
   "metadata": {},
   "source": [
    "Add polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9697e419-9f47-42a1-83b8-66275938aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=2)\n",
    "x_poly_train = poly_features.fit_transform(x_train)\n",
    "x_poly_test = poly_features.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0667498a",
   "metadata": {},
   "source": [
    "Next, we will choose a suitable model for our task. We will then tune the hyperparameters of the model, such as the regularization parameter and learning rate. We will use the training set to evaluate the model's performance, and the test set to assess its generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf53f86-fcfb-45b1-a7e6-d947837c00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg_poly = LinearRegression()\n",
    "forest_reg = RandomForestRegressor(random_state=0)\n",
    "tree_reg = DecisionTreeRegressor(random_state=0)\n",
    "svm_reg = SVR()\n",
    "ridge_reg = Ridge(alpha=0.01)\n",
    "elastic_reg = ElasticNet(alpha=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "822fe64b",
   "metadata": {},
   "source": [
    "Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a34094-b566-4873-869f-171537ae5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(x_train, y_train)\n",
    "forest_reg.fit(x_train, y_train)\n",
    "tree_reg.fit(x_train, y_train)\n",
    "svm_reg.fit(x_train, y_train)\n",
    "lin_reg_poly.fit(x_poly_train, y_train)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "elastic_reg.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0392abf9",
   "metadata": {},
   "source": [
    "Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f4658a-22e6-42ae-aa0e-aa9d1fe6e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin_reg = lin_reg.predict(x_test)\n",
    "y_pred_forest_reg = forest_reg.predict(x_test)\n",
    "y_pred_tree_reg = tree_reg.predict(x_test)\n",
    "y_pred_svm_reg = svm_reg.predict(x_test)\n",
    "y_pred_lin_poly_reg = lin_reg_poly.predict(x_poly_test)\n",
    "y_pred_ridge_reg = ridge_reg.predict(x_test)\n",
    "y_pred_elastic_reg = elastic_reg.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3dc2648",
   "metadata": {},
   "source": [
    "Evaluate the models using R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e6eb85-b263-4f26-8949-649e462a9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_lin_reg = r2_score(y_test, y_pred_lin_reg)\n",
    "r2_forest_reg = r2_score(y_test, y_pred_forest_reg)\n",
    "r2_tree_reg = r2_score(y_test, y_pred_tree_reg)\n",
    "r2_svm_reg = r2_score(y_test, y_pred_svm_reg)\n",
    "r2_lin_poly_reg = r2_score(y_test, y_pred_lin_poly_reg)\n",
    "r2_ridge_reg = r2_score(y_test, y_pred_ridge_reg)\n",
    "r2_elastic_reg = r2_score(y_test, y_pred_elastic_reg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "504031fd",
   "metadata": {},
   "source": [
    "Print the R2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857168f0-6ad5-4c09-9a36-0039671059d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Linear Regression: 0.8077385461717139\n",
      "R2 score for Random Forest Regressor: 0.5359454177405851\n",
      "R2 score for Decision Tree Regressor: 0.2252831575440949\n",
      "R2 score for Support Vector Machine Regressor: 0.44705646229285234\n",
      "R2 score for Linear Regression with Polynomial Features: 0.8239102808377585\n",
      "R2 score for Ridge Regression: 0.8087179499700691\n",
      "R2 score for Elastic Net Regression: 0.912611435559477\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 score for Linear Regression:\", r2_lin_reg)\n",
    "print(\"R2 score for Random Forest Regressor:\", r2_forest_reg)\n",
    "print(\"R2 score for Decision Tree Regressor:\", r2_tree_reg)\n",
    "print(\"R2 score for Support Vector Machine Regressor:\", r2_svm_reg)\n",
    "print(\"R2 score for Linear Regression with Polynomial Features:\", r2_lin_poly_reg)\n",
    "print(\"R2 score for Ridge Regression:\", r2_ridge_reg)\n",
    "print(\"R2 score for Elastic Net Regression:\", r2_elastic_reg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f032849c",
   "metadata": {},
   "source": [
    "Finally, we have used cross-validation to evaluate the model's R2 score. We expected a R2 score of at least 0.85. We achieved this score with the Elastice Net Regression, indicating that these models are suitable for our task.\n",
    "\n",
    "\n",
    "We can be confident that our model is ready to predict the amount of electricity produced by the windfarm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
